{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toonify_Yourself",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/Toonify-Yourself/blob/master/Toonify_Yourself.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc",
        "colab_type": "text"
      },
      "source": [
        "# セットアップ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YFk46FLM9qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/cedro3/Toonify-Yourself.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLBsk1IMwYe5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG1a92dav088",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd Toonify-Yourself\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "# フォルダーの作成\n",
        "!mkdir aligned\n",
        "!mkdir generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTyjn-DEwDVO",
        "colab_type": "text"
      },
      "source": [
        "# BaseモデルとBlendedモデルのダウンロード\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwVXBFaSuoIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseモデル(ffhqモデル)とblendedモデルのダウンロード\n",
        "import pretrained_networks\n",
        "\n",
        "# use my copy of the blended model to save Doron's download bandwidth\n",
        "# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n",
        "#blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\"\n",
        "blended_url = \"https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59\" \n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
        "_, _, Gs = pretrained_networks.load_networks(ffhq_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4y4tW16rdvk",
        "colab_type": "text"
      },
      "source": [
        "# 関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE5k3jE0mYvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像表示\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = glob.glob(folder)\n",
        "    files.sort()\n",
        "    images=[]\n",
        "    for i in range(len(files)):\n",
        "        img = Image.open(files[i])    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示\n",
        "import PIL.Image\n",
        "def display(latents):\n",
        "    \n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  \n",
        "    fig = plt.figure(figsize=(30, 40))   \n",
        "    for i in range(len(latents)):\n",
        "        vec = latents[i].reshape(1,18,512)\n",
        "        images =  Gs_blended.components.synthesis.run(vec, randomize_noise=False, **synthesis_kwargs)  \n",
        "        images = images.transpose((0,2,3,1))     \n",
        "        PIL.Image.fromarray(images[0], 'RGB')   \n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images[0])\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "  \n",
        "\n",
        "# 潜在変数(latents)の順番を指定して、トランジションのGIFを作成する\n",
        "import os\n",
        "\n",
        "def generate_gif(latents, idx):\n",
        "\n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "\n",
        "    image_gif = []\n",
        "    os.makedirs('my/gif', exist_ok=True)\n",
        "    for j in range(len(idx)-1):\n",
        "        for i in range(20):\n",
        "            latent = latents[idx[j]]+(latents[idx[j+1]]-latents[idx[j]])*i/19\n",
        "            latent = latent.reshape(1, 18, 512)\n",
        "            images =  Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs) \n",
        "            images = images.transpose((0,2,3,1)) \n",
        "            image_one = PIL.Image.fromarray(images[0], 'RGB')\n",
        "            image_gif.append(image_one.resize((256,256))) \n",
        "\n",
        "    image_gif[0].save('./my/gif/anime.gif', save_all=True, append_images=image_gif[1:],\n",
        "                      duration=100, loop=0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1NWI3iYaHuP",
        "colab_type": "text"
      },
      "source": [
        "# 用意した画像から顔画像を切り取る\n",
        "rawフォルダーの画像から顔画像を切り取り、alignedフォルダーに保存する "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLUH060th5oQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 顔画像の切り取り\n",
        "!python align_images.py raw aligned\n",
        "display_pic('./aligned/*.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkzaYkrbaU34",
        "colab_type": "text"
      },
      "source": [
        "# 潜在変数wを求める\n",
        "alignedフォルダーの顔画像から潜在変数wを求め、潜在変数wを generated/＊.npy に保存し、潜在変数wから生成した画像を generated/＊.png に保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldHXNMYhnYC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 顔画像の潜在変数を求める\n",
        "!python project_images.py --num-steps 500 aligned generated\n",
        "display_pic('./generated/*.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjRx7Rmzayyc",
        "colab_type": "text"
      },
      "source": [
        "# アニメ顔を生成する\n",
        "潜在変数(generated/＊.npy)を読み込み、blended モデルでアニメ画像を保存(generate/＊-toon.png)し、潜在変数はlatentsに保存する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHQgAO2yqaew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# アニメ顔を生成する\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from pathlib import Path\n",
        "\n",
        "latent_dir = Path(\"generated\")\n",
        "latents = sorted(latent_dir.glob(\"*.npy\"))\n",
        "\n",
        "for i, latent_file in enumerate(latents):\n",
        "  latent = np.load(latent_file)\n",
        "  latent = np.expand_dims(latent,axis=0)\n",
        "  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
        "  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\n",
        "  \n",
        "  if i == 0:\n",
        "    latents = latent\n",
        "  else:\n",
        "    latents = np.concatenate([latents, latent])  \n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示する\n",
        "display(latents)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgC4mywDeRor",
        "colab_type": "text"
      },
      "source": [
        "# トランジションGIFを作成する\n",
        "潜在変数(latents)の順番(リスト形式)を指定して、トランジションGIFを作成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwFHxy2V-uVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# トランジションGIFを作成する\n",
        "from IPython.display import Image\n",
        "generate_gif(latents,[0,1,2,0])\n",
        "Image('./my/gif/anime.gif', format='png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}